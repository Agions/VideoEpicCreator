#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸“ä¸šAIåœºæ™¯åˆ†æç»„ä»¶ - æ”¯æŒè§†é¢‘å†…å®¹åˆ†æã€åœºæ™¯åˆ†å‰²ã€ç‰©ä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æç­‰åŠŸèƒ½
é›†æˆè®¡ç®—æœºè§†è§‰å’ŒNLPæŠ€æœ¯ï¼Œæä¾›æ™ºèƒ½è§†é¢‘åˆ†æè§£å†³æ–¹æ¡ˆ
"""

import asyncio
import json
import time
import cv2
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, 
    QComboBox, QLineEdit, QGridLayout, QGroupBox, QCheckBox,
    QTabWidget, QSlider, QSpinBox, QFormLayout, QFileDialog,
    QRadioButton, QButtonGroup, QFrame, QScrollArea, QDialog,
    QDialogButtonBox, QDoubleSpinBox, QProgressBar, QTextEdit,
    QMessageBox, QSplitter, QTreeWidget, QTreeWidgetItem,
    QListWidget, QListWidgetItem, QToolButton, QMenu,
    QApplication, QSizePolicy, QSpacerItem, QTextBrowser,
    QTableWidget, QTableWidgetItem, QHeaderView, QGraphicsView,
    QGraphicsScene, QGraphicsPixmapItem, QGraphicsRectItem,
    QGraphicsTextItem, QColorDialog, QSlider
)
from PyQt6.QtCore import Qt, pyqtSignal, QTimer, QThread, QSize, QPoint, QRectF, QPointF
from PyQt6.QtGui import QIcon, QPixmap, QFont, QPainter, QColor, QPen, QBrush, QImage

from app.ai.enhanced_ai_manager import EnhancedAIManager
from app.ai.cost_manager import ChineseLLMCostManager, CostTier
from app.config.settings_manager import SettingsManager
from ..professional_ui_system import ProfessionalStyleEngine, ColorScheme, FontScheme


class AnalysisType(Enum):
    """åˆ†æç±»å‹"""
    SCENE_SEGMENTATION = "scene_segmentation"      # åœºæ™¯åˆ†å‰²
    OBJECT_DETECTION = "object_detection"          # ç‰©ä½“è¯†åˆ«
    FACE_RECOGNITION = "face_recognition"          # äººè„¸è¯†åˆ«
    EMOTION_ANALYSIS = "emotion_analysis"          # æƒ…æ„Ÿåˆ†æ
    ACTION_RECOGNITION = "action_recognition"      # åŠ¨ä½œè¯†åˆ«
    COLOR_ANALYSIS = "color_analysis"              # è‰²å½©åˆ†æ
    COMPOSITION_ANALYSIS = "composition_analysis"  # æ„å›¾åˆ†æ
    QUALITY_ASSESSMENT = "quality_assessment"      # è´¨é‡è¯„ä¼°


class DetectionLevel(Enum):
    """æ£€æµ‹çº§åˆ«"""
    BASIC = "åŸºç¡€"                        # åŸºç¡€æ£€æµ‹
    DETAILED = "è¯¦ç»†"                     # è¯¦ç»†æ£€æµ‹
    PROFESSIONAL = "ä¸“ä¸š"                  # ä¸“ä¸šæ£€æµ‹
    EXPERT = "ä¸“å®¶"                       # ä¸“å®¶æ£€æµ‹


@dataclass
class SceneSegment:
    """åœºæ™¯ç‰‡æ®µ"""
    start_time: float
    end_time: float
    thumbnail: np.ndarray = None
    description: str = ""
    key_objects: List[str] = None
    emotions: List[str] = None
    actions: List[str] = None
    quality_score: float = 0.0
    
    def __post_init__(self):
        if self.key_objects is None:
            self.key_objects = []
        if self.emotions is None:
            self.emotions = []
        if self.actions is None:
            self.actions = []


@dataclass
class DetectedObject:
    """æ£€æµ‹åˆ°çš„ç‰©ä½“"""
    label: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # (x, y, width, height)
    attributes: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.attributes is None:
            self.attributes = {}


@dataclass
class AnalysisResult:
    """åˆ†æç»“æœ"""
    analysis_id: str
    video_file: str
    analysis_type: AnalysisType
    scene_segments: List[SceneSegment] = None
    detected_objects: List[DetectedObject] = None
    emotion_timeline: List[Dict[str, Any]] = None
    action_timeline: List[Dict[str, Any]] = None
    color_palette: List[str] = None
    composition_score: float = 0.0
    overall_quality: float = 0.0
    recommendations: List[str] = None
    processing_time: float = 0.0
    created_at: float = None
    
    def __post_init__(self):
        if self.scene_segments is None:
            self.scene_segments = []
        if self.detected_objects is None:
            self.detected_objects = []
        if self.emotion_timeline is None:
            self.emotion_timeline = []
        if self.action_timeline is None:
            self.action_timeline = []
        if self.color_palette is None:
            self.color_palette = []
        if self.recommendations is None:
            self.recommendations = []
        if self.created_at is None:
            self.created_at = time.time()


@dataclass
class AnalysisRequest:
    """åˆ†æè¯·æ±‚"""
    request_id: str
    video_file: str
    analysis_type: AnalysisType
    detection_level: DetectionLevel = DetectionLevel.DETAILED
    enable_face_detection: bool = True
    enable_emotion_analysis: bool = True
    enable_action_recognition: bool = True
    enable_color_analysis: bool = True
    enable_quality_assessment: bool = True
    scene_threshold: float = 0.3
    min_segment_duration: float = 2.0
    max_segment_duration: float = 30.0
    selected_model: str = "auto"
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()


class AISceneAnalyzer(QWidget):
    """ä¸“ä¸šAIåœºæ™¯åˆ†æå™¨"""
    
    # ä¿¡å·å®šä¹‰
    analysis_started = pyqtSignal(str)                        # åˆ†æå¼€å§‹
    analysis_progress = pyqtSignal(str, float, str)           # åˆ†æè¿›åº¦ (request_id, progress, status)
    analysis_completed = pyqtSignal(str, object)       # åˆ†æå®Œæˆ
    analysis_error = pyqtSignal(str, str)                     # åˆ†æé”™è¯¯
    scene_detected = pyqtSignal(SceneSegment)                 # åœºæ™¯æ£€æµ‹åˆ°
    object_detected = pyqtSignal(DetectedObject)               # ç‰©ä½“æ£€æµ‹åˆ°
    emotion_updated = pyqtSignal(float, str)                  # æƒ…æ„Ÿæ›´æ–° (time, emotion)
    export_ready = pyqtSignal(str, str)                       # å¯¼å‡ºå‡†å¤‡å®Œæˆ
    
    def __init__(self, ai_manager: EnhancedAIManager, settings_manager: SettingsManager, parent=None):
        super().__init__(parent)
        self.ai_manager = ai_manager
        self.settings_manager = settings_manager
        self.cost_manager = ai_manager.cost_manager
        
        # æ ·å¼å¼•æ“
        self.style_engine = ProfessionalStyleEngine()
        
        # åˆ†æçŠ¶æ€
        self.current_analysis: AnalysisResult = None
        self.active_requests: Dict[str, AnalysisRequest] = {}
        self.request_counter = 0
        
        # è§†é¢‘å¤„ç†
        self.video_capture = None
        self.video_fps = 30
        self.video_frames = []
        
        # åˆå§‹åŒ–UI
        self._init_ui()
        self._connect_signals()
        self._load_settings()
        
    def _init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(20, 20, 20, 20)
        main_layout.setSpacing(16)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        self.tab_widget = QTabWidget()
        
        # åˆ†æè®¾ç½®æ ‡ç­¾é¡µ
        settings_tab = self._create_settings_tab()
        self.tab_widget.addTab(settings_tab, "âš™ï¸ åˆ†æè®¾ç½®")
        
        # åœºæ™¯åˆ†ææ ‡ç­¾é¡µ
        scene_tab = self._create_scene_tab()
        self.tab_widget.addTab(scene_tab, "ğŸ¬ åœºæ™¯åˆ†æ")
        
        # ç‰©ä½“è¯†åˆ«æ ‡ç­¾é¡µ
        object_tab = self._create_object_tab()
        self.tab_widget.addTab(object_tab, "ğŸ” ç‰©ä½“è¯†åˆ«")
        
        # æƒ…æ„Ÿåˆ†ææ ‡ç­¾é¡µ
        emotion_tab = self._create_emotion_tab()
        self.tab_widget.addTab(emotion_tab, "ğŸ˜Š æƒ…æ„Ÿåˆ†æ")
        
        # è´¨é‡è¯„ä¼°æ ‡ç­¾é¡µ
        quality_tab = self._create_quality_tab()
        self.tab_widget.addTab(quality_tab, "ğŸ“Š è´¨é‡è¯„ä¼°")
        
        main_layout.addWidget(self.tab_widget)
        
        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
        control_layout = QHBoxLayout()
        
        # é¢„è§ˆæŒ‰é’®
        preview_btn = QPushButton("ğŸ‘ï¸ è§†é¢‘é¢„è§ˆ")
        preview_btn.clicked.connect(self.preview_video)
        control_layout.addWidget(preview_btn)
        
        control_layout.addStretch()
        
        # åˆ†ææŒ‰é’®
        self.analyze_btn = QPushButton("ğŸš€ å¼€å§‹åˆ†æ")
        self.analyze_btn.clicked.connect(self.start_analysis)
        self.analyze_btn.setObjectName("analyze_btn")
        self.analyze_btn.setMinimumHeight(50)
        control_layout.addWidget(self.analyze_btn)
        
        main_layout.addLayout(control_layout)
        
        # è¿›åº¦æ˜¾ç¤º
        self.progress_widget = self._create_progress_widget()
        self.progress_widget.setVisible(False)
        main_layout.addWidget(self.progress_widget)
        
    def _create_settings_tab(self) -> QWidget:
        """åˆ›å»ºåˆ†æè®¾ç½®æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # è§†é¢‘æ–‡ä»¶é€‰æ‹©
        file_group = QGroupBox("è§†é¢‘æ–‡ä»¶")
        file_layout = QFormLayout(file_group)
        
        self.video_file_input = QLineEdit()
        self.video_file_input.setPlaceholderText("é€‰æ‹©è§†é¢‘æ–‡ä»¶")
        file_layout.addRow("è§†é¢‘æ–‡ä»¶:", self.video_file_input)
        
        browse_btn = QPushButton("ğŸ“ æµè§ˆ")
        browse_btn.clicked.connect(self.browse_video_file)
        file_layout.addRow("", browse_btn)
        
        layout.addWidget(file_group)
        
        # åˆ†æç±»å‹é€‰æ‹©
        type_group = QGroupBox("åˆ†æç±»å‹")
        type_layout = QVBoxLayout(type_group)
        
        # åˆ†æç±»å‹ç½‘æ ¼
        type_grid = QGridLayout()
        
        analysis_types = [
            ("ğŸ¬", "åœºæ™¯åˆ†å‰²", AnalysisType.SCENE_SEGMENTATION),
            ("ğŸ”", "ç‰©ä½“è¯†åˆ«", AnalysisType.OBJECT_DETECTION),
            ("ğŸ‘¤", "äººè„¸è¯†åˆ«", AnalysisType.FACE_RECOGNITION),
            ("ğŸ˜Š", "æƒ…æ„Ÿåˆ†æ", AnalysisType.EMOTION_ANALYSIS),
            ("ğŸƒ", "åŠ¨ä½œè¯†åˆ«", AnalysisType.ACTION_RECOGNITION),
            ("ğŸ¨", "è‰²å½©åˆ†æ", AnalysisType.COLOR_ANALYSIS),
            ("ğŸ“", "æ„å›¾åˆ†æ", AnalysisType.COMPOSITION_ANALYSIS),
            ("â­", "è´¨é‡è¯„ä¼°", AnalysisType.QUALITY_ASSESSMENT)
        ]
        
        self.analysis_checkboxes = {}
        
        for i, (icon, name, analysis_type) in enumerate(analysis_types):
            checkbox = QCheckBox(f"{icon} {name}")
            checkbox.setProperty("analysis_type", analysis_type.value)
            self.analysis_checkboxes[analysis_type] = checkbox
            type_grid.addWidget(checkbox, i // 4, i % 4)
        
        # é»˜è®¤é€‰æ‹©åŸºç¡€åˆ†æç±»å‹
        self.analysis_checkboxes[AnalysisType.SCENE_SEGMENTATION].setChecked(True)
        self.analysis_checkboxes[AnalysisType.OBJECT_DETECTION].setChecked(True)
        self.analysis_checkboxes[AnalysisType.EMOTION_ANALYSIS].setChecked(True)
        
        type_layout.addLayout(type_grid)
        
        # å…¨é€‰/å–æ¶ˆå…¨é€‰
        select_layout = QHBoxLayout()
        
        select_all_btn = QPushButton("âœ… å…¨é€‰")
        select_all_btn.clicked.connect(self.select_all_analysis_types)
        select_layout.addWidget(select_all_btn)
        
        select_none_btn = QPushButton("âŒ å–æ¶ˆå…¨é€‰")
        select_none_btn.clicked.connect(self.select_none_analysis_types)
        select_layout.addWidget(select_none_btn)
        
        select_layout.addStretch()
        
        type_layout.addLayout(select_layout)
        
        layout.addWidget(type_group)
        
        # æ£€æµ‹çº§åˆ«
        level_group = QGroupBox("æ£€æµ‹çº§åˆ«")
        level_layout = QHBoxLayout(level_group)
        
        self.level_group = QButtonGroup()
        
        for level in DetectionLevel:
            radio = QRadioButton(level.value)
            radio.setProperty("detection_level", level.value)
            self.level_group.addButton(radio)
            level_layout.addWidget(radio)
        
        # é»˜è®¤é€‰æ‹©è¯¦ç»†æ£€æµ‹
        self.level_group.buttons()[1].setChecked(True)
        
        layout.addWidget(level_group)
        
        # é«˜çº§è®¾ç½®
        advanced_group = QGroupBox("é«˜çº§è®¾ç½®")
        advanced_layout = QFormLayout(advanced_group)
        
        # åœºæ™¯åˆ†å‰²é˜ˆå€¼
        self.scene_threshold_slider = QSlider(Qt.Orientation.Horizontal)
        self.scene_threshold_slider.setRange(10, 90)
        self.scene_threshold_slider.setValue(30)
        self.scene_threshold_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.scene_threshold_label = QLabel("0.3")
        
        threshold_layout = QHBoxLayout()
        threshold_layout.addWidget(self.scene_threshold_slider)
        threshold_layout.addWidget(self.scene_threshold_label)
        advanced_layout.addRow("åœºæ™¯åˆ†å‰²é˜ˆå€¼:", threshold_layout)
        
        # ç‰‡æ®µæ—¶é•¿é™åˆ¶
        duration_layout = QHBoxLayout()
        
        self.min_duration_spin = QDoubleSpinBox()
        self.min_duration_spin.setRange(0.5, 10.0)
        self.min_duration_spin.setValue(2.0)
        self.min_duration_spin.setSuffix(" ç§’")
        duration_layout.addWidget(self.min_duration_spin)
        
        duration_layout.addWidget(QLabel(" - "))
        
        self.max_duration_spin = QDoubleSpinBox()
        self.max_duration_spin.setRange(5.0, 120.0)
        self.max_duration_spin.setValue(30.0)
        self.max_duration_spin.setSuffix(" ç§’")
        duration_layout.addWidget(self.max_duration_spin)
        
        advanced_layout.addRow("ç‰‡æ®µæ—¶é•¿:", duration_layout)
        
        # AIæ¨¡å‹é€‰æ‹©
        self.analysis_model_combo = QComboBox()
        self._populate_analysis_models()
        advanced_layout.addRow("AIæ¨¡å‹:", self.analysis_model_combo)
        
        layout.addWidget(advanced_group)
        
        layout.addStretch()
        
        return widget
    
    def _create_scene_tab(self) -> QWidget:
        """åˆ›å»ºåœºæ™¯åˆ†ææ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # åœºæ™¯æ—¶é—´è½´
        timeline_group = QGroupBox("åœºæ™¯æ—¶é—´è½´")
        timeline_layout = QVBoxLayout(timeline_group)
        
        self.scene_timeline = QListWidget()
        self.scene_timeline.setMaximumHeight(200)
        self.scene_timeline.itemClicked.connect(self.on_scene_selected)
        timeline_layout.addWidget(self.scene_timeline)
        
        layout.addWidget(timeline_group)
        
        # åœºæ™¯è¯¦æƒ…
        detail_group = QGroupBox("åœºæ™¯è¯¦æƒ…")
        detail_layout = QVBoxLayout(detail_group)
        
        self.scene_detail_browser = QTextBrowser()
        self.scene_detail_browser.setMaximumHeight(200)
        detail_layout.addWidget(self.scene_detail_browser)
        
        layout.addWidget(detail_group)
        
        # åœºæ™¯ç¼©ç•¥å›¾
        thumbnail_group = QGroupBox("åœºæ™¯ç¼©ç•¥å›¾")
        thumbnail_layout = QHBoxLayout(thumbnail_group)
        
        self.prev_scene_btn = QPushButton("â¬…ï¸ ä¸Šä¸€ä¸ª")
        self.prev_scene_btn.clicked.connect(self.prev_scene)
        thumbnail_layout.addWidget(self.prev_scene_btn)
        
        self.scene_thumbnail = QLabel()
        self.scene_thumbnail.setMinimumSize(320, 180)
        self.scene_thumbnail.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scene_thumbnail.setStyleSheet("border: 1px solid #ccc; background-color: #f0f0f0;")
        thumbnail_layout.addWidget(self.scene_thumbnail)
        
        self.next_scene_btn = QPushButton("ä¸‹ä¸€ä¸ª â¡ï¸")
        self.next_scene_btn.clicked.connect(self.next_scene)
        thumbnail_layout.addWidget(self.next_scene_btn)
        
        layout.addWidget(thumbnail_group)
        
        layout.addStretch()
        
        return widget
    
    def _create_object_tab(self) -> QWidget:
        """åˆ›å»ºç‰©ä½“è¯†åˆ«æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # ç‰©ä½“æ£€æµ‹è§†å›¾
        detection_group = QGroupBox("ç‰©ä½“æ£€æµ‹")
        detection_layout = QVBoxLayout(detection_group)
        
        # å›¾å½¢è§†å›¾
        self.detection_view = QGraphicsView()
        self.detection_scene = QGraphicsScene()
        self.detection_view.setScene(self.detection_scene)
        self.detection_view.setMinimumHeight(300)
        detection_layout.addWidget(self.detection_view)
        
        layout.addWidget(detection_group)
        
        # æ£€æµ‹ç»“æœåˆ—è¡¨
        result_group = QGroupBox("æ£€æµ‹ç»“æœ")
        result_layout = QVBoxLayout(result_group)
        
        self.object_list = QListWidget()
        self.object_list.setMaximumHeight(200)
        self.object_list.itemClicked.connect(self.on_object_selected)
        result_layout.addWidget(self.object_list)
        
        layout.addWidget(result_group)
        
        # ç‰©ä½“ç»Ÿè®¡
        stats_group = QGroupBox("ç‰©ä½“ç»Ÿè®¡")
        stats_layout = QFormLayout(stats_group)
        
        self.total_objects_label = QLabel("0")
        stats_layout.addRow("æ£€æµ‹åˆ°çš„ç‰©ä½“æ€»æ•°:", self.total_objects_label)
        
        self.unique_objects_label = QLabel("0")
        stats_layout.addRow("ç‰©ä½“ç±»åˆ«æ•°:", self.unique_objects_label)
        
        self.confidence_avg_label = QLabel("0%")
        stats_layout.addRow("å¹³å‡ç½®ä¿¡åº¦:", self.confidence_avg_label)
        
        layout.addWidget(stats_group)
        
        layout.addStretch()
        
        return widget
    
    def _create_emotion_tab(self) -> QWidget:
        """åˆ›å»ºæƒ…æ„Ÿåˆ†ææ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # æƒ…æ„Ÿæ—¶é—´è½´
        emotion_timeline_group = QGroupBox("æƒ…æ„Ÿæ—¶é—´è½´")
        emotion_timeline_layout = QVBoxLayout(emotion_timeline_group)
        
        self.emotion_chart = QWidget()
        self.emotion_chart.setMinimumHeight(200)
        self.emotion_chart.setStyleSheet("border: 1px solid #ccc; background-color: #f9f9f9;")
        emotion_timeline_layout.addWidget(self.emotion_chart)
        
        layout.addWidget(emotion_timeline_group)
        
        # æƒ…æ„Ÿç»Ÿè®¡
        emotion_stats_group = QGroupBox("æƒ…æ„Ÿç»Ÿè®¡")
        emotion_stats_layout = QGridLayout(emotion_stats_group)
        
        # æƒ…æ„Ÿç±»å‹
        emotions = ["å¼€å¿ƒ", "æ‚²ä¼¤", "æ„¤æ€’", "æƒŠè®¶", "ææƒ§", "åŒæ¶", "ä¸­æ€§"]
        self.emotion_bars = {}
        
        for i, emotion in enumerate(emotions):
            label = QLabel(f"{emotion}:")
            emotion_stats_layout.addWidget(label, i, 0)
            
            bar = QProgressBar()
            bar.setRange(0, 100)
            bar.setValue(0)
            emotion_stats_layout.addWidget(bar, i, 1)
            
            value_label = QLabel("0%")
            emotion_stats_layout.addWidget(value_label, i, 2)
            
            self.emotion_bars[emotion] = {"bar": bar, "label": value_label}
        
        layout.addWidget(emotion_stats_group)
        
        # æƒ…æ„Ÿè¯¦æƒ…
        emotion_detail_group = QGroupBox("æƒ…æ„Ÿè¯¦æƒ…")
        emotion_detail_layout = QVBoxLayout(emotion_detail_group)
        
        self.emotion_detail_browser = QTextBrowser()
        self.emotion_detail_browser.setMaximumHeight(150)
        emotion_detail_layout.addWidget(self.emotion_detail_browser)
        
        layout.addWidget(emotion_detail_group)
        
        layout.addStretch()
        
        return widget
    
    def _create_quality_tab(self) -> QWidget:
        """åˆ›å»ºè´¨é‡è¯„ä¼°æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # æ•´ä½“è´¨é‡è¯„åˆ†
        overall_group = QGroupBox("æ•´ä½“è´¨é‡è¯„åˆ†")
        overall_layout = QVBoxLayout(overall_group)
        
        self.quality_score_display = QLabel("ç­‰å¾…åˆ†æ...")
        self.quality_score_display.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.quality_score_display.setStyleSheet("font-size: 48px; font-weight: bold; color: #2196F3;")
        overall_layout.addWidget(self.quality_score_display)
        
        self.quality_description = QLabel("è¯·å…ˆè¿›è¡Œè§†é¢‘åˆ†æ")
        self.quality_description.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.quality_description.setWordWrap(True)
        overall_layout.addWidget(self.quality_description)
        
        layout.addWidget(overall_group)
        
        # è´¨é‡æŒ‡æ ‡
        metrics_group = QGroupBox("è´¨é‡æŒ‡æ ‡")
        metrics_layout = QFormLayout(metrics_group)
        
        # å„ç§è´¨é‡æŒ‡æ ‡
        self.brightness_score = QProgressBar()
        self.brightness_score.setRange(0, 100)
        metrics_layout.addRow("äº®åº¦è¯„åˆ†:", self.brightness_score)
        
        self.contrast_score = QProgressBar()
        self.contrast_score.setRange(0, 100)
        metrics_layout.addRow("å¯¹æ¯”åº¦è¯„åˆ†:", self.contrast_score)
        
        self.sharpness_score = QProgressBar()
        self.sharpness_score.setRange(0, 100)
        metrics_layout.addRow("æ¸…æ™°åº¦è¯„åˆ†:", self.sharpness_score)
        
        self.stability_score = QProgressBar()
        self.stability_score.setRange(0, 100)
        metrics_layout.addRow("ç¨³å®šæ€§è¯„åˆ†:", self.stability_score)
        
        self.composition_score = QProgressBar()
        self.composition_score.setRange(0, 100)
        metrics_layout.addRow("æ„å›¾è¯„åˆ†:", self.composition_score)
        
        self.audio_quality_score = QProgressBar()
        self.audio_quality_score.setRange(0, 100)
        metrics_layout.addRow("éŸ³é¢‘è´¨é‡:", self.audio_quality_score)
        
        layout.addWidget(metrics_group)
        
        # æ”¹è¿›å»ºè®®
        recommendations_group = QGroupBox("æ”¹è¿›å»ºè®®")
        recommendations_layout = QVBoxLayout(recommendations_group)
        
        self.recommendations_list = QListWidget()
        self.recommendations_list.setMaximumHeight(200)
        recommendations_layout.addWidget(self.recommendations_list)
        
        layout.addWidget(recommendations_group)
        
        layout.addStretch()
        
        return widget
    
    def _create_progress_widget(self) -> QWidget:
        """åˆ›å»ºè¿›åº¦æ˜¾ç¤ºç»„ä»¶"""
        widget = QFrame()
        widget.setObjectName("progress_widget")
        widget.setFrameStyle(QFrame.Shape.StyledPanel)
        
        layout = QVBoxLayout(widget)
        
        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        layout.addWidget(self.progress_bar)
        
        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("å‡†å¤‡å°±ç»ª")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(self.status_label)
        
        # è¯¦ç»†ä¿¡æ¯
        self.detail_label = QLabel("")
        self.detail_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(self.detail_label)
        
        # å–æ¶ˆæŒ‰é’®
        cancel_layout = QHBoxLayout()
        
        self.cancel_btn = QPushButton("âŒ å–æ¶ˆåˆ†æ")
        self.cancel_btn.clicked.connect(self.cancel_analysis)
        cancel_layout.addWidget(self.cancel_btn)
        
        cancel_layout.addStretch()
        
        layout.addLayout(cancel_layout)
        
        return widget
    
    def _populate_analysis_models(self):
        """å¡«å……åˆ†ææ¨¡å‹ä¸‹æ‹‰æ¡†"""
        self.analysis_model_combo.clear()
        self.analysis_model_combo.addItem("ğŸ¤– è‡ªåŠ¨é€‰æ‹©", "auto")
        
        # æ·»åŠ æ”¯æŒçš„åˆ†ææ¨¡å‹
        analysis_models = [
            ("qianwen", "é€šä¹‰åƒé—®"),
            ("zhipu", "æ™ºè°±AI"),
            ("hunyuan", "è…¾è®¯æ··å…ƒ"),
            ("deepseek", "DeepSeek")
        ]
        
        for model_id, model_name in analysis_models:
            self.analysis_model_combo.addItem(model_name, model_id)
    
    def _connect_signals(self):
        """è¿æ¥ä¿¡å·"""
        # åœºæ™¯é˜ˆå€¼æ»‘å—
        self.scene_threshold_slider.valueChanged.connect(self.on_scene_threshold_changed)
        
        # AIç®¡ç†å™¨ä¿¡å·
        self.ai_manager.model_response_ready.connect(self.on_ai_response)
        
        # æ ‡ç­¾é¡µåˆ‡æ¢ä¿¡å·
        self.tab_widget.currentChanged.connect(self.on_tab_changed)
    
    def on_scene_threshold_changed(self, value):
        """åœºæ™¯é˜ˆå€¼å˜æ›´"""
        threshold = value / 100.0
        self.scene_threshold_label.setText(f"{threshold:.1f}")
    
    def on_tab_changed(self, index):
        """æ ‡ç­¾é¡µåˆ‡æ¢"""
        # å½“åˆ‡æ¢åˆ°ä¸åŒæ ‡ç­¾é¡µæ—¶ï¼Œæ›´æ–°ç›¸åº”çš„æ˜¾ç¤ºå†…å®¹
        self.update_tab_content(index)
    
    def update_tab_content(self, tab_index):
        """æ›´æ–°æ ‡ç­¾é¡µå†…å®¹"""
        if not self.current_analysis:
            return
        
        if tab_index == 1:  # åœºæ™¯åˆ†æ
            self.update_scene_analysis()
        elif tab_index == 2:  # ç‰©ä½“è¯†åˆ«
            self.update_object_detection()
        elif tab_index == 3:  # æƒ…æ„Ÿåˆ†æ
            self.update_emotion_analysis()
        elif tab_index == 4:  # è´¨é‡è¯„ä¼°
            self.update_quality_assessment()
    
    def browse_video_file(self):
        """æµè§ˆè§†é¢‘æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", 
            "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov *.mkv *.flv *.wmv *.webm)"
        )
        if file_path:
            self.video_file_input.setText(file_path)
            self.load_video_info(file_path)
    
    def load_video_info(self, file_path):
        """åŠ è½½è§†é¢‘ä¿¡æ¯"""
        try:
            self.video_capture = cv2.VideoCapture(file_path)
            if self.video_capture.isOpened():
                self.video_fps = self.video_capture.get(cv2.CAP_PROP_FPS)
                total_frames = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
                duration = total_frames / self.video_fps
                
                QMessageBox.information(self, "è§†é¢‘ä¿¡æ¯", 
                                      f"æ–‡ä»¶: {file_path}\n"
                                      f"å¸§ç‡: {self.video_fps:.2f} fps\n"
                                      f"æ€»å¸§æ•°: {total_frames}\n"
                                      f"æ—¶é•¿: {duration:.2f} ç§’")
            else:
                QMessageBox.warning(self, "è­¦å‘Š", "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"åŠ è½½è§†é¢‘å¤±è´¥: {str(e)}")
    
    def select_all_analysis_types(self):
        """é€‰æ‹©æ‰€æœ‰åˆ†æç±»å‹"""
        for checkbox in self.analysis_checkboxes.values():
            checkbox.setChecked(True)
    
    def select_none_analysis_types(self):
        """å–æ¶ˆé€‰æ‹©æ‰€æœ‰åˆ†æç±»å‹"""
        for checkbox in self.analysis_checkboxes.values():
            checkbox.setChecked(False)
    
    def start_analysis(self):
        """å¼€å§‹åˆ†æ"""
        if not self.video_file_input.text():
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·é€‰æ‹©è§†é¢‘æ–‡ä»¶")
            return
        
        # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†åˆ†æç±»å‹
        selected_types = [analysis_type for analysis_type, checkbox in self.analysis_checkboxes.items() if checkbox.isChecked()]
        if not selected_types:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·è‡³å°‘é€‰æ‹©ä¸€ç§åˆ†æç±»å‹")
            return
        
        # åˆ›å»ºåˆ†æè¯·æ±‚
        request = self.create_analysis_request(selected_types)
        self.active_requests[request.request_id] = request
        
        # æ˜¾ç¤ºè¿›åº¦
        self.progress_widget.setVisible(True)
        self.status_label.setText("æ­£åœ¨åˆ†æè§†é¢‘...")
        self.analyze_btn.setEnabled(False)
        
        # å‘é€ä¿¡å·
        self.analysis_started.emit(request.request_id)
        
        # å¼€å§‹åˆ†æ
        asyncio.create_task(self.execute_analysis(request))
    
    def create_analysis_request(self, selected_types: List[AnalysisType]) -> AnalysisRequest:
        """åˆ›å»ºåˆ†æè¯·æ±‚"""
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªé€‰ä¸­çš„åˆ†æç±»å‹ä½œä¸ºä¸»è¦ç±»å‹
        primary_type = selected_types[0]
        
        return AnalysisRequest(
            request_id=f"analysis_{self.request_counter}",
            video_file=self.video_file_input.text(),
            analysis_type=primary_type,
            detection_level=DetectionLevel(self.level_group.checkedButton().property("detection_level")),
            enable_face_detection=AnalysisType.FACE_RECOGNITION in selected_types,
            enable_emotion_analysis=AnalysisType.EMOTION_ANALYSIS in selected_types,
            enable_action_recognition=AnalysisType.ACTION_RECOGNITION in selected_types,
            enable_color_analysis=AnalysisType.COLOR_ANALYSIS in selected_types,
            enable_quality_assessment=AnalysisType.QUALITY_ASSESSMENT in selected_types,
            scene_threshold=self.scene_threshold_slider.value() / 100.0,
            min_segment_duration=self.min_duration_spin.value(),
            max_segment_duration=self.max_duration_spin.value(),
            selected_model=self.analysis_model_combo.currentData()
        )
    
    async def execute_analysis(self, request: AnalysisRequest):
        """æ‰§è¡Œåˆ†æ"""
        try:
            start_time = time.time()
            
            # åˆ›å»ºåˆ†æç»“æœ
            self.current_analysis = AnalysisResult(
                analysis_id=request.request_id,
                video_file=request.video_file,
                analysis_type=request.analysis_type
            )
            
            # åœºæ™¯åˆ†å‰²åˆ†æ
            if request.analysis_type == AnalysisType.SCENE_SEGMENTATION:
                await self.analyze_scene_segments(request)
            
            # ç‰©ä½“è¯†åˆ«åˆ†æ
            if request.enable_face_detection or request.analysis_type == AnalysisType.OBJECT_DETECTION:
                await self.analyze_objects(request)
            
            # æƒ…æ„Ÿåˆ†æ
            if request.enable_emotion_analysis:
                await self.analyze_emotions(request)
            
            # åŠ¨ä½œè¯†åˆ«
            if request.enable_action_recognition:
                await self.analyze_actions(request)
            
            # è‰²å½©åˆ†æ
            if request.enable_color_analysis:
                await self.analyze_colors(request)
            
            # è´¨é‡è¯„ä¼°
            if request.enable_quality_assessment:
                await self.assess_quality(request)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            self.current_analysis.processing_time = time.time() - start_time
            
            # æ›´æ–°UI
            self.update_analysis_results()
            
            self.progress_bar.setValue(100)
            self.status_label.setText("åˆ†æå®Œæˆ")
            
            # å‘é€ä¿¡å·
            self.analysis_completed.emit(request.request_id, self.current_analysis)
            
        except Exception as e:
            self.analysis_error.emit(request.request_id, str(e))
            self.status_label.setText(f"åˆ†æå¤±è´¥: {str(e)}")
            
        finally:
            # æ¸…ç†è¯·æ±‚
            if request.request_id in self.active_requests:
                del self.active_requests[request.request_id]
            
            # æ¢å¤æŒ‰é’®çŠ¶æ€
            self.analyze_btn.setEnabled(True)
            
            # éšè—è¿›åº¦æ¡ï¼ˆå»¶è¿Ÿï¼‰
            QTimer.singleShot(3000, lambda: self.progress_widget.setVisible(False))
    
    async def analyze_scene_segments(self, request: AnalysisRequest):
        """åˆ†æåœºæ™¯ç‰‡æ®µ"""
        self.analysis_progress.emit(request.request_id, 10.0, "æ­£åœ¨åˆ†æåœºæ™¯ç‰‡æ®µ...")
        
        # æ¨¡æ‹Ÿåœºæ™¯åˆ†å‰²åˆ†æ
        await asyncio.sleep(1)
        
        # ç”Ÿæˆç¤ºä¾‹åœºæ™¯ç‰‡æ®µ
        scene_segments = []
        
        # å‡è®¾è§†é¢‘æ—¶é•¿ä¸º60ç§’
        video_duration = 60.0
        current_time = 0.0
        
        scene_descriptions = [
            "å¼€åœºä»‹ç»ï¼Œä¸»æŒäººå‡ºé•œ",
            "ä¸»è¦å†…å®¹è®²è§£ï¼Œäº§å“å±•ç¤º",
            "ç”¨æˆ·è®¿è°ˆï¼Œå®é™…åº”ç”¨åœºæ™¯",
            "æŠ€æœ¯æ¼”ç¤ºï¼ŒåŠŸèƒ½ä»‹ç»",
            "æ€»ç»“å›é¡¾ï¼Œæ„Ÿè°¢è§‚çœ‹"
        ]
        
        for i, description in enumerate(scene_descriptions):
            segment_duration = min(12.0, video_duration - current_time)
            
            segment = SceneSegment(
                start_time=current_time,
                end_time=current_time + segment_duration,
                description=description,
                key_objects=["äººç‰©", "èƒŒæ™¯"],
                emotions=["ä¸­æ€§"],
                actions=["è¯´è¯", "æ‰‹åŠ¿"],
                quality_score=0.8 + (i * 0.05)
            )
            
            scene_segments.append(segment)
            current_time += segment_duration
        
        self.current_analysis.scene_segments = scene_segments
        
        # æ›´æ–°åœºæ™¯æ—¶é—´è½´
        self.update_scene_timeline(scene_segments)
        
        self.analysis_progress.emit(request.request_id, 30.0, "åœºæ™¯ç‰‡æ®µåˆ†æå®Œæˆ")
    
    async def analyze_objects(self, request: AnalysisRequest):
        """åˆ†æç‰©ä½“è¯†åˆ«"""
        self.analysis_progress.emit(request.request_id, 35.0, "æ­£åœ¨è¯†åˆ«ç‰©ä½“...")
        
        await asyncio.sleep(1)
        
        # ç”Ÿæˆç¤ºä¾‹ç‰©ä½“æ£€æµ‹ç»“æœ
        detected_objects = [
            DetectedObject(
                label="äººç‰©",
                confidence=0.95,
                bbox=(100, 50, 200, 300),
                attributes={"gender": "æœªçŸ¥", "age_range": "æˆäºº"}
            ),
            DetectedObject(
                label="æ¡Œå­",
                confidence=0.88,
                bbox=(50, 250, 400, 100),
                attributes={"material": "æœ¨è´¨", "color": "æ£•è‰²"}
            ),
            DetectedObject(
                label="ç”µè„‘",
                confidence=0.92,
                bbox=(150, 200, 150, 100),
                attributes={"type": "ç¬”è®°æœ¬", "brand": "æœªçŸ¥"}
            ),
            DetectedObject(
                label="ä¹¦ç±",
                confidence=0.76,
                bbox=(300, 220, 80, 60),
                attributes={"count": "3", "category": "æŠ€æœ¯"}
            )
        ]
        
        self.current_analysis.detected_objects = detected_objects
        
        # æ›´æ–°ç‰©ä½“æ£€æµ‹æ˜¾ç¤º
        self.update_object_detection_display(detected_objects)
        
        self.analysis_progress.emit(request.request_id, 50.0, "ç‰©ä½“è¯†åˆ«å®Œæˆ")
    
    async def analyze_emotions(self, request: AnalysisRequest):
        """åˆ†ææƒ…æ„Ÿ"""
        self.analysis_progress.emit(request.request_id, 55.0, "æ­£åœ¨åˆ†ææƒ…æ„Ÿ...")
        
        await asyncio.sleep(1)
        
        # ç”Ÿæˆç¤ºä¾‹æƒ…æ„Ÿåˆ†æç»“æœ
        emotion_timeline = []
        
        # å‡è®¾60ç§’è§†é¢‘ï¼Œæ¯5ç§’åˆ†æä¸€æ¬¡
        for i in range(0, 60, 5):
            emotions = {
                "å¼€å¿ƒ": 0.6 + (i * 0.01),
                "ä¸­æ€§": 0.3 - (i * 0.005),
                "æƒŠè®¶": 0.1 + (i * 0.002)
            }
            
            emotion_timeline.append({
                "time": i,
                "emotions": emotions,
                "dominant_emotion": max(emotions, key=emotions.get)
            })
        
        self.current_analysis.emotion_timeline = emotion_timeline
        
        # æ›´æ–°æƒ…æ„Ÿåˆ†ææ˜¾ç¤º
        self.update_emotion_analysis_display(emotion_timeline)
        
        self.analysis_progress.emit(request.request_id, 70.0, "æƒ…æ„Ÿåˆ†æå®Œæˆ")
    
    async def analyze_actions(self, request: AnalysisRequest):
        """åˆ†æåŠ¨ä½œè¯†åˆ«"""
        self.analysis_progress.emit(request.request_id, 75.0, "æ­£åœ¨è¯†åˆ«åŠ¨ä½œ...")
        
        await asyncio.sleep(0.5)
        
        # ç”Ÿæˆç¤ºä¾‹åŠ¨ä½œè¯†åˆ«ç»“æœ
        action_timeline = [
            {"time": 0, "action": "ç«™ç«‹", "confidence": 0.9},
            {"time": 5, "action": "è¯´è¯", "confidence": 0.95},
            {"time": 15, "action": "æ‰‹åŠ¿", "confidence": 0.88},
            {"time": 25, "action": "æŒ‡å‘", "confidence": 0.82},
            {"time": 35, "action": "æ“ä½œ", "confidence": 0.91},
            {"time": 45, "action": "å¾®ç¬‘", "confidence": 0.87}
        ]
        
        self.current_analysis.action_timeline = action_timeline
        
        self.analysis_progress.emit(request.request_id, 80.0, "åŠ¨ä½œè¯†åˆ«å®Œæˆ")
    
    async def analyze_colors(self, request: AnalysisRequest):
        """åˆ†æè‰²å½©"""
        self.analysis_progress.emit(request.request_id, 85.0, "æ­£åœ¨åˆ†æè‰²å½©...")
        
        await asyncio.sleep(0.5)
        
        # ç”Ÿæˆç¤ºä¾‹è‰²å½©åˆ†æç»“æœ
        color_palette = [
            "#2C3E50",  # æ·±è“ç°
            "#3498DB",  # è“è‰²
            "#E74C3C",  # çº¢è‰²
            "#F39C12",  # æ©™è‰²
            "#27AE60"   # ç»¿è‰²
        ]
        
        self.current_analysis.color_palette = color_palette
        
        self.analysis_progress.emit(request.request_id, 90.0, "è‰²å½©åˆ†æå®Œæˆ")
    
    async def assess_quality(self, request: AnalysisRequest):
        """è¯„ä¼°è´¨é‡"""
        self.analysis_progress.emit(request.request_id, 92.0, "æ­£åœ¨è¯„ä¼°è´¨é‡...")
        
        await asyncio.sleep(0.8)
        
        # ç”Ÿæˆç¤ºä¾‹è´¨é‡è¯„ä¼°ç»“æœ
        quality_scores = {
            "brightness": 85,
            "contrast": 78,
            "sharpness": 82,
            "stability": 90,
            "composition": 75,
            "audio_quality": 88
        }
        
        overall_quality = sum(quality_scores.values()) / len(quality_scores)
        
        self.current_analysis.overall_quality = overall_quality
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        recommendations = [
            "å»ºè®®æé«˜è§†é¢‘å¯¹æ¯”åº¦ï¼Œå¢å¼ºç”»é¢å±‚æ¬¡æ„Ÿ",
            "å¯ä»¥ä¼˜åŒ–æ„å›¾ï¼Œéµå¾ªä¸‰åˆ†æ³•åˆ™",
            "å»ºè®®ä½¿ç”¨æ›´ç¨³å®šçš„æ‹æ‘„è®¾å¤‡",
            "è€ƒè™‘å¢åŠ èƒŒæ™¯éŸ³ä¹æå‡æ•´ä½“è´¨é‡"
        ]
        
        self.current_analysis.recommendations = recommendations
        
        # æ›´æ–°è´¨é‡è¯„ä¼°æ˜¾ç¤º
        self.update_quality_assessment_display(quality_scores, overall_quality, recommendations)
        
        self.analysis_progress.emit(request.request_id, 100.0, "è´¨é‡è¯„ä¼°å®Œæˆ")
    
    def update_analysis_results(self):
        """æ›´æ–°åˆ†æç»“æœæ˜¾ç¤º"""
        if not self.current_analysis:
            return
        
        # æ›´æ–°å½“å‰æ ‡ç­¾é¡µçš„å†…å®¹
        current_tab = self.tab_widget.currentIndex()
        self.update_tab_content(current_tab)
    
    def update_scene_timeline(self, scene_segments: List[SceneSegment]):
        """æ›´æ–°åœºæ™¯æ—¶é—´è½´"""
        self.scene_timeline.clear()
        
        for i, segment in enumerate(scene_segments):
            start_time_str = self._format_time_for_display(segment.start_time)
            end_time_str = self._format_time_for_display(segment.end_time)
            duration = segment.end_time - segment.start_time
            
            item_text = f"{i+1:02d}. {start_time_str} - {end_time_str} ({duration:.1f}s) {segment.description}"
            
            item = QListWidgetItem(item_text)
            item.setData(Qt.ItemDataRole.UserRole, segment)
            self.scene_timeline.addItem(item)
    
    def update_object_detection_display(self, detected_objects: List[DetectedObject]):
        """æ›´æ–°ç‰©ä½“æ£€æµ‹æ˜¾ç¤º"""
        # æ¸…ç©ºåœºæ™¯
        self.detection_scene.clear()
        
        # æ·»åŠ èƒŒæ™¯å›¾ç‰‡ï¼ˆç¤ºä¾‹ï¼‰
        background_rect = QGraphicsRectItem(0, 0, 640, 480)
        background_rect.setBrush(QBrush(QColor(240, 240, 240)))
        self.detection_scene.addItem(background_rect)
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for obj in detected_objects:
            x, y, w, h = obj.bbox
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            rect_item = QGraphicsRectItem(x, y, w, h)
            rect_item.setPen(QPen(QColor(255, 0, 0), 2))
            self.detection_scene.addItem(rect_item)
            
            # æ·»åŠ æ ‡ç­¾
            label_text = f"{obj.label} ({obj.confidence:.0%})"
            label_item = QGraphicsTextItem(label_text)
            label_item.setPos(x, y - 20)
            label_item.setDefaultTextColor(QColor(255, 0, 0))
            self.detection_scene.addItem(label_item)
        
        # æ›´æ–°ç‰©ä½“åˆ—è¡¨
        self.object_list.clear()
        
        for obj in detected_objects:
            item_text = f"{obj.label} - ç½®ä¿¡åº¦: {obj.confidence:.0%}"
            item = QListWidgetItem(item_text)
            item.setData(Qt.ItemDataRole.UserRole, obj)
            self.object_list.addItem(item)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.total_objects_label.setText(str(len(detected_objects)))
        
        unique_objects = len(set(obj.label for obj in detected_objects))
        self.unique_objects_label.setText(str(unique_objects))
        
        avg_confidence = sum(obj.confidence for obj in detected_objects) / len(detected_objects)
        self.confidence_avg_label.setText(f"{avg_confidence:.0%}")
    
    def update_emotion_analysis_display(self, emotion_timeline: List[Dict[str, Any]]):
        """æ›´æ–°æƒ…æ„Ÿåˆ†ææ˜¾ç¤º"""
        if not emotion_timeline:
            return
        
        # è®¡ç®—æƒ…æ„Ÿç»Ÿè®¡
        emotion_totals = {}
        emotion_counts = {}
        
        for entry in emotion_timeline:
            emotions = entry["emotions"]
            for emotion, score in emotions.items():
                if emotion not in emotion_totals:
                    emotion_totals[emotion] = 0
                    emotion_counts[emotion] = 0
                emotion_totals[emotion] += score
                emotion_counts[emotion] += 1
        
        # æ›´æ–°æƒ…æ„Ÿæ¡å½¢å›¾
        for emotion, data in self.emotion_bars.items():
            if emotion in emotion_totals:
                avg_score = emotion_totals[emotion] / emotion_counts[emotion]
                percentage = avg_score * 100
                data["bar"].setValue(int(percentage))
                data["label"].setText(f"{percentage:.0f}%")
            else:
                data["bar"].setValue(0)
                data["label"].setText("0%")
        
        # æ›´æ–°æƒ…æ„Ÿè¯¦æƒ…
        detail_text = "<h3>æƒ…æ„Ÿåˆ†æè¯¦æƒ…</h3>"
        for emotion, data in self.emotion_bars.items():
            if emotion in emotion_totals:
                avg_score = emotion_totals[emotion] / emotion_counts[emotion]
                detail_text += f"<p><b>{emotion}:</b> å¹³å‡å¼ºåº¦ {avg_score:.2f}</p>"
        
        self.emotion_detail_browser.setHtml(detail_text)
    
    def update_quality_assessment_display(self, quality_scores: Dict[str, float], 
                                       overall_quality: float, recommendations: List[str]):
        """æ›´æ–°è´¨é‡è¯„ä¼°æ˜¾ç¤º"""
        # æ›´æ–°æ•´ä½“è¯„åˆ†
        self.quality_score_display.setText(f"{overall_quality:.0f}")
        
        # æ›´æ–°è¯„åˆ†æè¿°
        if overall_quality >= 90:
            description = "ä¼˜ç§€ - è§†é¢‘è´¨é‡å¾ˆé«˜ï¼Œå»ºè®®ä¿æŒå½“å‰æ ‡å‡†"
        elif overall_quality >= 80:
            description = "è‰¯å¥½ - è§†é¢‘è´¨é‡è¾ƒå¥½ï¼Œæœ‰å°‘é‡æ”¹è¿›ç©ºé—´"
        elif overall_quality >= 70:
            description = "ä¸€èˆ¬ - è§†é¢‘è´¨é‡ä¸­ç­‰ï¼Œå»ºè®®è¿›è¡Œä¸€äº›ä¼˜åŒ–"
        elif overall_quality >= 60:
            description = "éœ€æ”¹è¿› - è§†é¢‘è´¨é‡æœ‰å¾…æå‡"
        else:
            description = "è¾ƒå·® - è§†é¢‘è´¨é‡éœ€è¦å¤§å¹…æ”¹è¿›"
        
        self.quality_description.setText(description)
        
        # æ›´æ–°å„é¡¹æŒ‡æ ‡
        self.brightness_score.setValue(int(quality_scores.get("brightness", 0)))
        self.contrast_score.setValue(int(quality_scores.get("contrast", 0)))
        self.sharpness_score.setValue(int(quality_scores.get("sharpness", 0)))
        self.stability_score.setValue(int(quality_scores.get("stability", 0)))
        self.composition_score.setValue(int(quality_scores.get("composition", 0)))
        self.audio_quality_score.setValue(int(quality_scores.get("audio_quality", 0)))
        
        # æ›´æ–°æ”¹è¿›å»ºè®®
        self.recommendations_list.clear()
        for recommendation in recommendations:
            self.recommendations_list.addItem(recommendation)
    
    def on_scene_selected(self, item):
        """åœºæ™¯é€‰æ‹©äº‹ä»¶"""
        segment = item.data(Qt.ItemDataRole.UserRole)
        if segment:
            self.display_scene_details(segment)
    
    def display_scene_details(self, segment: SceneSegment):
        """æ˜¾ç¤ºåœºæ™¯è¯¦æƒ…"""
        detail_html = f"""
        <h3>åœºæ™¯è¯¦æƒ…</h3>
        <p><b>æ—¶é—´:</b> {self._format_time_for_display(segment.start_time)} - {self._format_time_for_display(segment.end_time)}</p>
        <p><b>æ—¶é•¿:</b> {segment.end_time - segment.start_time:.1f} ç§’</p>
        <p><b>æè¿°:</b> {segment.description}</p>
        <p><b>å…³é”®ç‰©ä½“:</b> {', '.join(segment.key_objects)}</p>
        <p><b>æƒ…æ„Ÿ:</b> {', '.join(segment.emotions)}</p>
        <p><b>åŠ¨ä½œ:</b> {', '.join(segment.actions)}</p>
        <p><b>è´¨é‡è¯„åˆ†:</b> {segment.quality_score:.2f}</p>
        """
        
        self.scene_detail_browser.setHtml(detail_html)
        
        # æ˜¾ç¤ºç¼©ç•¥å›¾ï¼ˆç¤ºä¾‹ï¼‰
        self.scene_thumbnail.setText("åœºæ™¯ç¼©ç•¥å›¾\n(ç¤ºä¾‹)")
    
    def on_object_selected(self, item):
        """ç‰©ä½“é€‰æ‹©äº‹ä»¶"""
        obj = item.data(Qt.ItemDataRole.UserRole)
        if obj:
            self.highlight_object(obj)
    
    def highlight_object(self, obj: DetectedObject):
        """é«˜äº®æ˜¾ç¤ºç‰©ä½“"""
        # åœ¨å›¾å½¢è§†å›¾ä¸­é«˜äº®æ˜¾ç¤ºé€‰ä¸­çš„ç‰©ä½“
        for item in self.detection_scene.items():
            if isinstance(item, QGraphicsRectItem):
                x, y, w, h = obj.bbox
                if item.rect() == QRectF(x, y, w, h):
                    item.setPen(QPen(QColor(0, 255, 0), 3))
                else:
                    item.setPen(QPen(QColor(255, 0, 0), 2))
    
    def prev_scene(self):
        """ä¸Šä¸€ä¸ªåœºæ™¯"""
        current_row = self.scene_timeline.currentRow()
        if current_row > 0:
            self.scene_timeline.setCurrentRow(current_row - 1)
    
    def next_scene(self):
        """ä¸‹ä¸€ä¸ªåœºæ™¯"""
        current_row = self.scene_timeline.currentRow()
        if current_row < self.scene_timeline.count() - 1:
            self.scene_timeline.setCurrentRow(current_row + 1)
    
    def preview_video(self):
        """é¢„è§ˆè§†é¢‘"""
        if not self.video_file_input.text():
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶")
            return
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨è§†é¢‘é¢„è§ˆåŠŸèƒ½
        QMessageBox.information(self, "è§†é¢‘é¢„è§ˆ", "è§†é¢‘é¢„è§ˆåŠŸèƒ½éœ€è¦é›†æˆè§†é¢‘æ’­æ”¾å™¨")
    
    def cancel_analysis(self):
        """å–æ¶ˆåˆ†æ"""
        # å–æ¶ˆæ‰€æœ‰æ´»è·ƒçš„åˆ†æè¯·æ±‚
        for request_id in list(self.active_requests.keys()):
            self.analysis_error.emit(request_id, "ç”¨æˆ·å–æ¶ˆ")
        
        self.active_requests.clear()
        self.progress_widget.setVisible(False)
        self.analyze_btn.setEnabled(True)
        self.status_label.setText("åˆ†æå·²å–æ¶ˆ")
    
    def export_analysis_results(self):
        """å¯¼å‡ºåˆ†æç»“æœ"""
        if not self.current_analysis:
            QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„åˆ†æç»“æœ")
            return
        
        # é€‰æ‹©å¯¼å‡ºæ ¼å¼
        file_path, _ = QFileDialog.getSaveFileName(
            self, "å¯¼å‡ºåˆ†æç»“æœ", "", 
            "JSONæ–‡ä»¶ (*.json);;PDFæŠ¥å‘Š (*.pdf);;CSVæ–‡ä»¶ (*.csv)"
        )
        
        if not file_path:
            return
        
        try:
            # ç”Ÿæˆå¯¼å‡ºæ•°æ®
            export_data = {
                "analysis_id": self.current_analysis.analysis_id,
                "video_file": self.current_analysis.video_file,
                "analysis_type": self.current_analysis.analysis_type.value,
                "created_at": self.current_analysis.created_at,
                "processing_time": self.current_analysis.processing_time,
                "overall_quality": self.current_analysis.overall_quality,
                "scene_segments": [
                    {
                        "start_time": seg.start_time,
                        "end_time": seg.end_time,
                        "description": seg.description,
                        "quality_score": seg.quality_score
                    }
                    for seg in self.current_analysis.scene_segments
                ],
                "detected_objects": [
                    {
                        "label": obj.label,
                        "confidence": obj.confidence,
                        "bbox": obj.bbox
                    }
                    for obj in self.current_analysis.detected_objects
                ],
                "recommendations": self.current_analysis.recommendations
            }
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            self.export_ready.emit(file_path, "json")
            QMessageBox.information(self, "æˆåŠŸ", f"åˆ†æç»“æœå·²å¯¼å‡ºåˆ°ï¼š{file_path}")
            
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"å¯¼å‡ºå¤±è´¥ï¼š{str(e)}")
    
    def _format_time_for_display(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ç”¨äºæ˜¾ç¤º"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"
    
    def on_ai_response(self, model_provider, response):
        """AIå“åº”å¤„ç†"""
        if response.success:
            print(f"AIå“åº”æˆåŠŸ: {model_provider}")
        else:
            print(f"AIå“åº”å¤±è´¥: {model_provider} - {response.error_message}")
    
    def _load_settings(self):
        """åŠ è½½è®¾ç½®"""
        settings = self.settings_manager.get_setting("scene_analyzer", {})
        
        # åº”ç”¨è®¾ç½®
        if "default_detection_level" in settings:
            level = settings["default_detection_level"]
            for button in self.level_group.buttons():
                if button.property("detection_level") == level:
                    button.setChecked(True)
                    break
        
        if "scene_threshold" in settings:
            threshold = int(settings["scene_threshold"] * 100)
            self.scene_threshold_slider.setValue(threshold)
    
    def _save_settings(self):
        """ä¿å­˜è®¾ç½®"""
        settings = {
            "default_detection_level": self.level_group.checkedButton().property("detection_level"),
            "scene_threshold": self.scene_threshold_slider.value() / 100.0
        }
        
        self.settings_manager.set_setting("scene_analyzer", settings)
    
    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶"""
        self._save_settings()
        
        # é‡Šæ”¾è§†é¢‘èµ„æº
        if self.video_capture:
            self.video_capture.release()
        
        super().closeEvent(event)